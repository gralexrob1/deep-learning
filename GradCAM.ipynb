{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_ktag": "mATXpS/fTPhu"
   },
   "source": [
    "# Imports\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_ktag": "mATXpS/fTPhu"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import pickle\n",
    "import urllib.request\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import models, datasets, transforms\n",
    "from torchsummary import summary\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_ktag": "mATXpS/fTPhu"
   },
   "source": [
    "# Model\n",
    "\n",
    "![ResNet34](https://miro.medium.com/max/1050/1*Y-u7dH4WC-dXyn9jOG4w0w.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_ktag": "mATXpS/fTPhu"
   },
   "outputs": [],
   "source": [
    "resnet34 = models.resnet34(weights='ResNet34_Weights.IMAGENET1K_V1')\n",
    "resnet34.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary(resnet34, (3, 224, 224), device='cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_ktag": "mATXpS/fTPhu"
   },
   "source": [
    "# Inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_ktag": "mATXpS/fTPhu"
   },
   "outputs": [],
   "source": [
    "def preprocess_image(dir_path):\n",
    "    normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                     std=[0.229, 0.224, 0.225])\n",
    "    \n",
    "    dataset = datasets.ImageFolder(dir_path, transforms.Compose([\n",
    "            transforms.Resize(256), \n",
    "            transforms.CenterCrop(224),\n",
    "            transforms.ToTensor(),\n",
    "            normalize]))\n",
    "\n",
    "    return (dataset)\n",
    "\n",
    "if not os.path.exists(\"data\"):\n",
    "    os.mkdir(\"data\")\n",
    "if not os.path.exists(\"data/GradCAM/data\"):\n",
    "    os.mkdir(\"data/GradCAM/data\")\n",
    "    !cd data/GradCAM && wget \"https://www.lri.fr/~gcharpia/deeppractice/2023/TP2/TP2_images.zip\" && unzip TP2_images.zip\n",
    "\n",
    "dir_path = \"data\" \n",
    "dataset = preprocess_image(dir_path)\n",
    "\n",
    "print(dataset)\n",
    "print(dataset[0][0].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_ktag": "mATXpS/fTPhu"
   },
   "outputs": [],
   "source": [
    "classes = pickle.load(urllib.request.urlopen('https://gist.githubusercontent.com/yrevar/6135f1bd8dcf2e0cc683/raw/d133d61a09d7e5a3b36b8c111a8dd5c4b5d560ee/imagenet1000_clsid_to_human.pkl'))\n",
    "classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_label(model, image_index, top_n=1):\n",
    "\n",
    "    output = model(dataset[image_index][0].view(1, 3, 224, 224))\n",
    "\n",
    "    _, indices = torch.topk(output, top_n)\n",
    "    label_index = indices[0].numpy()[:top_n]\n",
    "    label_pred = [classes[i] for i in label_index]         \n",
    "    \n",
    "    return (label_index, label_pred)\n",
    "\n",
    "\n",
    "def labeled_plot(image_index, label):\n",
    "\n",
    "    input_image = Image.open(dataset.imgs[image_index][0]).convert('RGB')\n",
    "\n",
    "    plt.imshow(input_image)\n",
    "    plt.title(\" / \".join(label))\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "image_index = 5\n",
    "(label_index, label_name) = predict_label(resnet34, image_index, 3)\n",
    "print(label_index)\n",
    "print(label_name)\n",
    "labeled_plot(image_index, label_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_ktag": "mATXpS/fTPhu"
   },
   "source": [
    "# Grad-CAM \n",
    "\n",
    "**Overview**  \n",
    "Given an image, and a category (‘tiger cat’) as input, we forward-propagate the image through the model to obtain the `raw class scores` before softmax. The gradients are set to zero for all classes except the desired class (tiger cat), which is set to 1. This signal is then backpropagated to the `rectified convolutional feature map` of interest, where we can compute the coarse Grad-CAM localization (blue heatmap).\n",
    "\n",
    "*pug, pug-dog* | *tabby, tabby cat*\n",
    "\n",
    "![alt](https://raw.githubusercontent.com/jacobgil/pytorch-grad-cam/master/examples/dog.jpg) ![alt](https://raw.githubusercontent.com/jacobgil/pytorch-grad-cam/master/examples/cat.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet34.layer4\n",
    "list(resnet34.layer4.children())\n",
    "list(resnet34.layer4.children())[-1]\n",
    "list(list(resnet34.layer4.children())[-1].children())\n",
    "list(list(resnet34.layer4.children())[-1].children())[-1]\n",
    "\n",
    "target_layer = list(list(resnet34.layer4.children())[-1].children())[-1]\n",
    "str(target_layer.__class__).split(\".\")[-1][:-2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Both losses do the same thing.\n",
    "\n",
    "The ```MultiplicativeFiltergingLoss```sets gradients to 0 more literally\n",
    "by multiplicating output by the one-hot_encoded target.\n",
    "\n",
    "The ```FilteringLoss```  sets gradients to 0 more efficiently by filtering.\n",
    "\"\"\"\n",
    "\n",
    "class MultiplicativeFilteringLoss(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(FilteringLoss, self).__init__()\n",
    "\n",
    "    def forward(self, output, target):\n",
    "\n",
    "        value = sum(output * target).clone()\n",
    "\n",
    "        return value\n",
    "    \n",
    "\n",
    "class FilteringLoss(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(FilteringLoss, self).__init__()\n",
    "\n",
    "    def forward(self, output, target):\n",
    "\n",
    "        value = output[:, target].clone()\n",
    "\n",
    "        return value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GradCAM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradcam(image_index, label_index, model, target_layer):\n",
    "\n",
    "    # HOOK\n",
    "    activation = None\n",
    "    gradient = None\n",
    "\n",
    "    def get_activations_hook(module, input, output):\n",
    "        nonlocal activation\n",
    "        activation = output\n",
    "\n",
    "    def get_grads_hook(module, grad_input, grad_output):\n",
    "        nonlocal gradient\n",
    "        gradient = grad_output[0]\n",
    "\n",
    "    hook_activation = target_layer.register_forward_hook(get_activations_hook)\n",
    "    hook_gradient = target_layer.register_backward_hook(get_grads_hook)\n",
    "\n",
    "    # FORWARD\n",
    "    model.zero_grad()\n",
    "    input = dataset[image_index][0].view(1, 3, 224, 224)\n",
    "    input.requires_grad = True\n",
    "    output = model(input)\n",
    "\n",
    "    # BACKWARD\n",
    "\n",
    "    # ohe_target = torch.tensor(\n",
    "    #     [1 if i == label_index else 0 for i, _ in enumerate(output[0])],\n",
    "    #     dtype=torch.float\n",
    "    # ).reshape(output.shape)\n",
    "    # loss_fn = MultiplicativeFilteringLoss()\n",
    "    # loss = loss_fn(output, ohe_target)\n",
    "    # loss.backward()\n",
    "\n",
    "    loss_fn = FilteringLoss()\n",
    "    loss = loss_fn(output, torch.tensor([label_index]))\n",
    "    loss.backward()\n",
    "\n",
    "    # CLEANUP\n",
    "    hook_activation.remove()\n",
    "    hook_gradient.remove()\n",
    "\n",
    "    # GRADCAM\n",
    "    weights = torch.mean(gradient, dim=(2, 3), keepdim=True)\n",
    "    grad_cam = torch.sum(weights * activation, dim=1, keepdim=True)\n",
    "    grad_cam = nn.functional.relu(grad_cam)\n",
    "\n",
    "    upsampled_grad_cam = nn.functional.interpolate(\n",
    "        grad_cam, size=(224, 224),\n",
    "        mode = 'bilinear', # 'nearest' doesn't work and the others do not work with our shape\n",
    "        align_corners=False\n",
    "    )\n",
    "\n",
    "    # VISUALIZATION\n",
    "    label = classes[label_index]\n",
    "    reference_image = input.detach().numpy()[0].transpose(1, 2, 0)\n",
    "    gradcam_heatmap = upsampled_grad_cam.detach().numpy()[0, 0, :, :]\n",
    "\n",
    "    # plt.imshow(reference_image)\n",
    "    # plt.imshow(gradcam_heatmap, cmap='jet', alpha=0.5)\n",
    "    # plt.title(label)\n",
    "    # plt.show()\n",
    "\n",
    "    return reference_image, gradcam_heatmap, label\n",
    "\n",
    "\n",
    "fig, axes = plt.subplots(1, len(label_index), figsize=(10,10))\n",
    "\n",
    "for i, label_i in enumerate(label_index):\n",
    "\n",
    "    image, heatmap, label = gradcam(image_index, label_i, resnet34, target_layer)\n",
    "\n",
    "    axes[i].imshow(image)\n",
    "    axes[i].imshow(heatmap, cmap='jet', alpha=0.5)\n",
    "    axes[i].set_title(label)\n",
    "    axes[i].axis('off')\n",
    "\n",
    "plt.tight_layout() \n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparisons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_gradcams(image_index, label_indexes, model, modules):\n",
    "\n",
    "    if len(modules) == 1:\n",
    "\n",
    "        fig, axes = plt.subplots(len(modules), len(label_indexes), figsize=(10,10))\n",
    "\n",
    "        for i, label_i in enumerate(label_indexes):\n",
    "\n",
    "            image, heatmap, label = gradcam(image_index, label_i, model, modules[0])\n",
    "\n",
    "            axes[i].imshow(image)\n",
    "            axes[i].imshow(heatmap, cmap='jet', alpha=0.5)\n",
    "            axes[i].set_title(label)\n",
    "            axes[i].axis('off')\n",
    "    \n",
    "    if len(modules) > 1 and len(label_indexes) > 1:\n",
    "\n",
    "        fig, axes = plt.subplots(len(modules), len(label_indexes), figsize=(10,10))\n",
    "\n",
    "        for j, module_j in enumerate(modules):\n",
    "            for i, label_i in enumerate(label_indexes):\n",
    "\n",
    "                image, heatmap, label = gradcam(image_index, label_i, model, module_j)\n",
    "\n",
    "                axes[j][i].imshow(image)\n",
    "                axes[j][i].imshow(heatmap, cmap='jet', alpha=0.5)\n",
    "                axes[j][i].set_title(label)\n",
    "                axes[j][i].axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layers_final_module = [\n",
    "    list(list(resnet34.layer4.children())[-1].children())[-1],\n",
    "    list(list(resnet34.layer3.children())[-1].children())[-1],\n",
    "    list(list(resnet34.layer2.children())[-1].children())[-1],\n",
    "    list(list(resnet34.layer1.children())[-1].children())[-1]\n",
    "]\n",
    "\n",
    "compare_gradcams(image_index, label_index, resnet34, layers_final_module)\n",
    "plt.suptitle('GradCAM accross layers')\n",
    "plt.tight_layout() \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer4_blocks_final_module = [\n",
    "    list(list(resnet34.layer4.children())[-1].children())[-1],\n",
    "    list(list(resnet34.layer4.children())[-2].children())[-1],\n",
    "    list(list(resnet34.layer4.children())[-3].children())[-1],\n",
    "]\n",
    "\n",
    "compare_gradcams(image_index, label_index, resnet34, layer4_blocks_final_module)\n",
    "plt.suptitle('GradCAM accross Layer 4 blocks')\n",
    "plt.tight_layout() \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer4_block_3_modules = [\n",
    "    list(list(resnet34.layer4.children())[-1].children())[-1],\n",
    "    list(list(resnet34.layer4.children())[-1].children())[-2],\n",
    "    list(list(resnet34.layer4.children())[-1].children())[-3],\n",
    "    list(list(resnet34.layer4.children())[-1].children())[-4],\n",
    "    list(list(resnet34.layer4.children())[-1].children())[-5]\n",
    "]\n",
    "\n",
    "compare_gradcams(image_index, label_index, resnet34, layer4_block_3_modules)\n",
    "plt.suptitle('GradCAM accross Layer 4 block 3 modules')\n",
    "plt.tight_layout() \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer4_block_2_modules = [\n",
    "    list(list(resnet34.layer4.children())[-2].children())[-1],\n",
    "    list(list(resnet34.layer4.children())[-2].children())[-2],\n",
    "    list(list(resnet34.layer4.children())[-2].children())[-3],\n",
    "    list(list(resnet34.layer4.children())[-2].children())[-4],\n",
    "    list(list(resnet34.layer4.children())[-2].children())[-5]\n",
    "]\n",
    "\n",
    "compare_gradcams(image_index, label_index, resnet34, layer4_block_2_modules)\n",
    "plt.suptitle('GradCAM accross Layer 4 Block 2 modules')\n",
    "plt.tight_layout() \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer4_block_1_modules = [\n",
    "    list(list(resnet34.layer4.children())[-3].children())[-1],\n",
    "    list(list(resnet34.layer4.children())[-3].children())[-2],\n",
    "    list(list(resnet34.layer4.children())[-3].children())[-3],\n",
    "    list(list(resnet34.layer4.children())[-3].children())[-4],\n",
    "    list(list(resnet34.layer4.children())[-3].children())[-5]\n",
    "]\n",
    "\n",
    "compare_gradcams(image_index, label_index, resnet34, layer4_block_1_modules)\n",
    "plt.suptitle('GradCAM accross Layer 4 Block 1 modules')\n",
    "plt.tight_layout() \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer3_block_1_modules = [\n",
    "    list(list(resnet34.layer3.children())[-3].children())[-1],\n",
    "    list(list(resnet34.layer3.children())[-3].children())[-2],\n",
    "    list(list(resnet34.layer3.children())[-3].children())[-3],\n",
    "    list(list(resnet34.layer3.children())[-3].children())[-4],\n",
    "    list(list(resnet34.layer3.children())[-3].children())[-5]\n",
    "]\n",
    "\n",
    "compare_gradcams(image_index, label_index, resnet34, layer3_block_1_modules)\n",
    "plt.suptitle('GradCAM accross Layer 3 Block 1 modules')\n",
    "plt.tight_layout() \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_layer = [\n",
    "    list(list(resnet34.layer4.children())[-1].children())[-5]\n",
    "]\n",
    "\n",
    "compare_gradcams(image_index, label_index, resnet34, test_layer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_ktag": "mATXpS/fTPhu"
   },
   "source": [
    "# Conclusion\n",
    "\n",
    "As we move up the layers and the modules inside the layers the results of GradCAM are less and less precise.\n",
    "The nearest from the output we are, the more precise the heatmap is, and as we go farther and farther the heatmap worsens.\n",
    "This is visibale at every level.\n",
    "\n",
    "It is interesting to see that as precision worsens not only the relevant pixels area decreases but once it has disappeared, the non relevant pixel area increases. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_ktag": "mATXpS/fTPhu"
   },
   "source": [
    "# GradCAM contributions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_ktag": "mATXpS/fTPhu"
   },
   "source": [
    "Grad-CAM allows to generate visual explanations for CNN-based network with the following advantages:\n",
    " - it works for **any** CNN-based network\n",
    " - it requires no architectural changes or re-training\n",
    " - explanations are class-specific\n",
    "\n",
    "GradCAM shows a proof-of-concept of how interpretable visualizations can help in diagnosing failure.\n",
    "It demonstrates that diagnosing image classification for seemingly unreasonable predictions can have\n",
    " reasonable explanations. Finally is can help in the identification of biases in datasets.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "kfiletag": "mATXpS/fTPhu",
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
